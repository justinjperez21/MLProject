# -*- coding: utf-8 -*-
"""ML_Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NqDjlH6nyyEJiH4vg-7ggdQ7PvJCttP_
"""

# Commented out IPython magic to ensure Python compatibility.
import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from tqdm.auto import tqdm
import os
import tensorflow as tf
from tensorflow import summary
import datetime
# %load_ext tensorboard

os.environ['WANDB_CONSOLE'] = 'off'

if torch.cuda.is_available():
 dev = "cuda:0"
else:
 dev = "cpu"
device = torch.device(dev)

'''pytorch dataloader is superior
# Preprocess data
#1. Flatten image to 28*28 length torch tensor
#2. Change category from a number to a one-hot vector


def PIL_to_flattened(x):
  return torch.flatten(torch.Tensor(np.array(x)))

#only valid for MNIST currently(# of categories = 10)
def category_to_vector(x):
  vec = torch.zeros(10) #have to change the number of categories when I use other datasets
  vec[x] = 1
  return vec

#separate and format data, where batch_dim = 0
images = torch.Tensor(size=(len(MNIST), 28*28))
labels = torch.Tensor(size=(len(MNIST), 10))

for i, data in enumerate(tqdm(MNIST)):
  images[i] = PIL_to_flattened(data[0])
  labels[i] = category_to_vector(data[1])
'''

#Will have to change this if I don't use dataset in torchvision
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5), (0.5))]) #from [0,1] to [-1,1]
     #transforms.Lambda(lambda x: torch.flatten(x))])

batch_size = 32

trainset = torchvision.datasets.MNIST(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.MNIST(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                         shuffle=False, num_workers=2)

def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()


# get some random training images
dataiter = iter(trainloader)
images, labels = next(dataiter)
#images = images.flatten(1,3)
print(images.shape)
# show images
imshow(torchvision.utils.make_grid(images))

latent_size = 100

class GeneratorModel(nn.Module):
  def __init__(self):
    super(GeneratorModel, self).__init__()

    self.layers = nn.Sequential(nn.Linear(in_features=latent_size, out_features=128), nn.LeakyReLU(),
                                nn.Linear(in_features=128, out_features=256), nn.LeakyReLU(),
                                nn.Linear(in_features=256, out_features=512), nn.LeakyReLU(),
                                #nn.Linear(in_features=512, out_features=512), nn.LeakyReLU(),
                                #nn.Linear(in_features=512, out_features=512), nn.LeakyReLU(),
                                nn.Linear(in_features=512, out_features=28*28), nn.Tanh())

  def forward(self, x):
    return self.layers(x)

class DiscriminatorModel(nn.Module):
  def __init__(self):
    super(DiscriminatorModel, self).__init__()

    self.layers = nn.Sequential(#nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1),
                                nn.Linear(in_features=28*28, out_features=512), nn.LeakyReLU(),
                                nn.Linear(in_features=512, out_features=256), nn.LeakyReLU(),
                                #nn.Linear(in_features=256, out_features=256), nn.LeakyReLU(),
                                #nn.Linear(in_features=256, out_features=128), nn.LeakyReLU(),
                                nn.Linear(in_features=256, out_features=1), nn.Sigmoid())

  def forward(self, x):
    return self.layers(x)

#Training setup
total_epochs = 500
G = GeneratorModel()
D = DiscriminatorModel()
G.to(device)
D.to(device)
G_optimizer = torch.optim.Adam(G.parameters(), lr=3e-4)
D_optimizer = torch.optim.Adam(D.parameters(), lr=3e-4)

G_train_loss_list = []
D_train_loss_list = []
G_test_loss_list = []
D_test_loss_list = []

G_Train_iter = 0
G_Test_iter = 0
D_Train_iter = 0
D_Test_iter = 0

noise_mean = 0
noise_std = 10

G_max_batches_per_epoch = 20
D_max_batches_per_epoch = 15

#G(torch.Tensor(size=(10,100))).shape#.detach().unflatten(1, (28,28))[0].shape

# Commented out IPython magic to ensure Python compatibility.
current_time = str(datetime.datetime.now().timestamp())

train_log_dir = 'logs/tensorboard/train/' + current_time
#test_log_dir = 'logs/tensorboard/test/' + current_time

train_summary_writer = summary.create_file_writer(train_log_dir)
#test_summary_writer = summary.create_file_writer(test_log_dir)

# %tensorboard --logdir logs/tensorboard
#orange color hex: #f06c04

#Training Loop

for epoch in tqdm(range(total_epochs)):
  #Discriminator epoch
  for i, (inputs, labels) in enumerate(tqdm(trainloader)):
    if i > D_max_batches_per_epoch: break
    inputs = inputs.flatten(1,3)

    #reset optimizer gradients for next batch
    D_optimizer.zero_grad(set_to_none=True)

    #generate fake data for batch
    noise_samples = torch.Tensor(size=(inputs.size(dim=0), latent_size))
    noise_samples.normal_(mean=noise_mean, std=noise_std)
    #noise_samples
    G_out = G(noise_samples.to(device))

    #forward pass on discriminator
    D_real = D(inputs.to(device))
    D_fake = D(G_out.to(device).detach())

    #Calculate loss and backward pass
    D_loss = (-torch.log(D_real) - torch.log(1 - D_fake)).mean()
    D_loss.backward()
    D_optimizer.step()

    D_train_loss_list.append(D_loss.item())

    with train_summary_writer.as_default():
          tf.summary.scalar('D Train loss', D_loss.mean().item(), step = D_Train_iter)#i + (epoch*len(trainloader)))

    D_Train_iter = D_Train_iter + 1

    for j, (val_inputs, val_labels) in enumerate((testloader)): #add tqdm later
      val_inputs = val_inputs.flatten(1,3)

      noise_samples = torch.Tensor(size=(val_inputs.size(dim=0), latent_size))
      noise_samples.normal_(mean=noise_mean, std=noise_std)
      G_out = G(noise_samples.to(device))

      D_real = D(val_inputs.to(device))
      D_fake = D(G_out.to(device))

      D_loss = (-torch.log(D_real) - torch.log(1 - D_fake)).mean()

      D_test_loss_list.append(D_loss.item())

      with train_summary_writer.as_default():
        tf.summary.scalar('D Test loss', D_loss.mean().item(), step = D_Test_iter)#i + j + epoch*len(testloader))

      D_Test_iter = D_Test_iter + 1

      break

  #Generator epoch
  for i, (inputs, labels) in enumerate(tqdm(trainloader)):
    if i > G_max_batches_per_epoch: break
    #reset optimizer gradients for next batch
    G_optimizer.zero_grad(set_to_none=True)
    #generate fake data for batch
    noise_samples = torch.Tensor(size=(inputs.size(dim=0), latent_size))
    noise_samples.normal_(mean=noise_mean, std=noise_std)
    #noise_samples
    G_out = G(noise_samples.to(device))

    #forward pass on discriminator
    D_fake = D(G_out.to(device))

    #Calculate loss and backward pass
    G_loss = -torch.log(D_fake).mean()#torch.log(1 - D_fake).mean()
    G_loss.backward()
    G_optimizer.step()

    G_train_loss_list.append(G_loss.mean().item())

    with train_summary_writer.as_default():
          tf.summary.scalar('G Train loss', G_loss.mean().item(), step = G_Train_iter)#i + (epoch*len(trainloader)))

    G_Train_iter = G_Train_iter + 1

    for j, (val_inputs, val_labels) in enumerate((testloader)): #add tqdm later
      noise_samples = torch.Tensor(size=(val_inputs.size(dim=0), latent_size))
      noise_samples.normal_(mean=noise_mean, std=noise_std)
      G_out = G(noise_samples.to(device))

      D_fake = D(G_out.to(device))

      G_loss = -torch.log(D_fake).mean()#torch.log(1 - D_fake).mean()

      G_test_loss_list.append(G_loss.mean().item())

      with train_summary_writer.as_default():
        tf.summary.scalar('G Test loss', G_loss.mean().item(), step = G_Test_iter)#i + j + epoch*len(testloader))

      G_Test_iter = G_Test_iter + 1

      break

  plt.imshow((G_out[0]+0.5).unflatten(dim=0,sizes=(28,28)).detach().cpu())

plot_start = 0
plot_end = plot_start + 100
plt.figure(figsize=(15,15))
plt.subplot(2, 1, 1)
plt.plot(np.array(G_train_loss_list)[plot_start:plot_end], label='G Train')
plt.plot(np.array(G_test_loss_list)[plot_start:plot_end], label='G Test')
plt.legend()
plt.subplot(2, 1, 2)
plt.plot(np.array(D_train_loss_list)[plot_start:plot_end], label='D Train')
plt.plot(np.array(D_test_loss_list)[plot_start:plot_end], label='D Test')
plt.legend()
plt.show()

noise_samples = torch.Tensor(size=(batch_size, latent_size))
noise_samples.normal_(mean=0, std=1)
G_out = G(noise_samples.to(device))
#D_fake = D(G_out)
#plt.imshow((noise_samples[0]).unflatten(dim=0,sizes=(10,10)).detach().cpu())
plt.imshow((G_out[0]+0.5).unflatten(dim=0,sizes=(28,28)).detach().cpu())